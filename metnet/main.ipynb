{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# nodes: 8591 \n",
      "# edges: 30081\n",
      "\n",
      "Removing self-loops...\n",
      "# nodes: 8591 \n",
      "# edges: 30026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30026/30026 [00:00<00:00, 607375.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct pathway predictions: 14\n",
      "Correct pathway predictions (%): 28.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from compound import Compound\n",
    "from reaction import Reaction\n",
    "from graph import Graph\n",
    "from data import Data\n",
    "\n",
    "# create class instances\n",
    "data = Data()\n",
    "graph = Graph()\n",
    "\n",
    "# read data from csv\n",
    "cpds = pd.read_csv('data/compounds_final.csv', index_col=0)\n",
    "rxns = pd.read_csv('data/reactions_final.csv', index_col=0)\n",
    "pairs = pd.read_csv('data/pairs_final.csv', index_col=0)\n",
    "cofactors = pd.read_csv('data/original/cofactors_KEGG.csv')\n",
    "\n",
    "# Create a Compound object for each row in the DataFrame and add it to the data\n",
    "for index, row in cpds.iterrows():\n",
    "    entry = row['Entry']\n",
    "    name = row['Names']\n",
    "    formula = row['Formula']\n",
    "    mw = row['mol_weight']\n",
    "    smiles = row['SMILES']\n",
    "    is_cofactor = row['Entry'] in cofactors['Entry'].values\n",
    "\n",
    "    compound = Compound(entry, name, formula, mw, smiles, is_cofactor)\n",
    "    data.add_element('compound', compound)\n",
    "\n",
    "# Create a Reaction object for each row in the DataFrame and add it to the data\n",
    "for index, row in rxns.iterrows():\n",
    "    entry = row['Entry']\n",
    "    name = row['Names']\n",
    "    compounds = row['Compound']\n",
    "    enzyme = row['EC Number']\n",
    "\n",
    "    reaction = Reaction(entry, name, compounds, enzyme)\n",
    "    data.add_element('reaction', reaction)\n",
    "\n",
    "\n",
    "# number of times a metabolite apperas on pairs dataset\n",
    "graph.get_number_of_occurences(pairs)\n",
    "\n",
    "# Create Graph\n",
    "graph.create_graph(data=data, pairs=pairs)\n",
    "\n",
    "''' \n",
    "*******************************************\n",
    "Validate the methods on validation datasets \n",
    "*******************************************\n",
    "'''\n",
    "######### VALIDATION SET FROM nicepath ###########\n",
    "test_cases = pd.read_csv('data/original/test_cases.csv')\n",
    "test_cases['source'] = test_cases['Pathway '].apply(lambda x: x.split(',')[0])\n",
    "test_cases['target'] = test_cases['Pathway '].apply(lambda x: x.split(',')[len(x.split(','))-1])\n",
    "test_cases['paths_list'] = test_cases['Pathway '].apply(lambda x: x.split(','))\n",
    "\n",
    "paths = graph.simple_weighted_shortest_path(test_cases=test_cases, data=data, method='mol_weight')\n",
    "\n",
    "# ######### NEW VALIDATION SET ###########\n",
    "# pyminer_test = pd.read_csv('data/original/pyminer_validation_set.csv', delimiter=';', header=None, names=['Pathway'])\n",
    "# pyminer_test['source'] = pyminer_test['Pathway'].apply(lambda x: x.split(',')[0])\n",
    "# pyminer_test['target'] = pyminer_test['Pathway'].apply(lambda x: x.split(',')[len(x.split(','))-1])\n",
    "# pyminer_test['paths_list'] = pyminer_test['Pathway'].apply(lambda x: x.split(','))\n",
    "\n",
    "# print('Simple weighted shortes paths:')\n",
    "# paths = graph.simple_weighted_shortest_path(test_cases=pyminer_test, data=data, method='mol_weight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save predicted paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "directory = 'data/results'\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "paths.to_csv('data/results/predicted_paths.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph learning and stuff to try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpd = data.get_compound_by_id('C00082')\n",
    "print(cpd)\n",
    "\n",
    "smile = cpd.smiles\n",
    "print(smile)\n",
    "\n",
    "correct_pathway_example = paths['Pathway'].iloc[1]\n",
    "print(correct_pathway_example)\n",
    "\n",
    "correct_subgraph = graph.G.subgraph(correct_pathway_example)\n",
    "print(correct_subgraph.nodes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GNN! (Maybe good)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Graph' object has no attribute 'G'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[118], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m gg \u001b[39m=\u001b[39m graph\u001b[39m.\u001b[39;49mG\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Graph' object has no attribute 'G'"
     ]
    }
   ],
   "source": [
    "gg = graph.G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.data import Data\n",
    "import torch_geometric\n",
    "import torch\n",
    "\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(input_dim, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, hidden_dim)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        # Global mean pooling to obtain graph-level representation\n",
    "        x = torch_geometric.nn.global_mean_pool(x, batch)\n",
    "        \n",
    "        # apply a final classifier\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph with 8591 nodes and 30026 edges\n"
     ]
    }
   ],
   "source": [
    "master_G = gg.copy()\n",
    "print(master_G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graphs: [<networkx.classes.graph.Graph object at 0x7f3761267fa0>, <networkx.classes.graph.Graph object at 0x7f375ba9d430>, <networkx.classes.graph.Graph object at 0x7f375ba9db50>, <networkx.classes.graph.Graph object at 0x7f375bb11be0>, <networkx.classes.graph.Graph object at 0x7f375bb110a0>, <networkx.classes.graph.Graph object at 0x7f375bb11b80>, <networkx.classes.graph.Graph object at 0x7f375bb11a30>, <networkx.classes.graph.Graph object at 0x7f375bb11dc0>, <networkx.classes.graph.Graph object at 0x7f375bb11ee0>, <networkx.classes.graph.Graph object at 0x7f37ff0a3310>, <networkx.classes.graph.Graph object at 0x7f37ff0a3760>, <networkx.classes.graph.Graph object at 0x7f37ff0a39a0>, <networkx.classes.graph.Graph object at 0x7f37ff0a3cd0>, <networkx.classes.graph.Graph object at 0x7f37ff0a3a00>, <networkx.classes.graph.Graph object at 0x7f37ff0a32e0>, <networkx.classes.graph.Graph object at 0x7f37ff0a3610>, <networkx.classes.graph.Graph object at 0x7f37ff0a3250>, <networkx.classes.graph.Graph object at 0x7f37ff0a32b0>, <networkx.classes.graph.Graph object at 0x7f37ff0a3850>, <networkx.classes.graph.Graph object at 0x7f375bb1f640>, <networkx.classes.graph.Graph object at 0x7f375bb1fc10>, <networkx.classes.graph.Graph object at 0x7f375bb1f220>, <networkx.classes.graph.Graph object at 0x7f37611c4be0>, <networkx.classes.graph.Graph object at 0x7f37613a9bb0>, <networkx.classes.graph.Graph object at 0x7f37613a9e80>, <networkx.classes.graph.Graph object at 0x7f37613a9d00>, <networkx.classes.graph.Graph object at 0x7f375b9c9310>, <networkx.classes.graph.Graph object at 0x7f3761209040>, <networkx.classes.graph.Graph object at 0x7f37611e1d90>, <networkx.classes.graph.Graph object at 0x7f37644b6760>, <networkx.classes.graph.Graph object at 0x7f37644b6670>, <networkx.classes.graph.Graph object at 0x7f375b6b3af0>, <networkx.classes.graph.Graph object at 0x7f375b6b3910>, <networkx.classes.graph.Graph object at 0x7f375b6b3670>, <networkx.classes.graph.Graph object at 0x7f375b6b39a0>, <networkx.classes.graph.Graph object at 0x7f375b6b3760>, <networkx.classes.graph.Graph object at 0x7f375b6b37f0>, <networkx.classes.graph.Graph object at 0x7f375b6b3be0>, <networkx.classes.graph.Graph object at 0x7f375ba3d3d0>, <networkx.classes.graph.Graph object at 0x7f3761201ac0>, <networkx.classes.graph.Graph object at 0x7f3764937be0>, <networkx.classes.graph.Graph object at 0x7f377ca6aac0>, <networkx.classes.graph.Graph object at 0x7f377c307e80>, <networkx.classes.graph.Graph object at 0x7f3761263580>, <networkx.classes.graph.Graph object at 0x7f3761263460>, <networkx.classes.graph.Graph object at 0x7f3761263940>, <networkx.classes.graph.Graph object at 0x7f3761263be0>, <networkx.classes.graph.Graph object at 0x7f3761263f40>, <networkx.classes.graph.Graph object at 0x7f3761263d30>, <networkx.classes.graph.Graph object at 0x7f3761263790>]\n",
      "Labels: [0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "graphs = []\n",
    "labels = []\n",
    "\n",
    "for row in range(len(paths)):\n",
    "    sg = master_G.subgraph(paths['Pathway'].iloc[row])\n",
    "    graphs.append(sg)\n",
    "\n",
    "    if paths['Correct'].iloc[row]: label = 1\n",
    "    else: label = 0\n",
    "\n",
    "    labels.append(label)\n",
    "\n",
    "print(\"Graphs:\", graphs)\n",
    "print(\"Labels:\", labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataBatch(x=[306, 1], edge_index=[2, 256], edge_attr=[256], y=[50], batch=[306], ptr=[51])\n"
     ]
    }
   ],
   "source": [
    "# Convert NetworkX graphs to PyG data\n",
    "data_list = []\n",
    "for graph, label in zip(graphs, labels):\n",
    "    # rename nodes to integers    \n",
    "    mapping = {node: idx for idx, node in enumerate(graph.nodes())}\n",
    "    graph = nx.relabel_nodes(graph, mapping)\n",
    "\n",
    "    # Convert NetworkX graph to PyG data\n",
    "    x = torch.tensor([graph.nodes[node]['mw'] for node in graph.nodes], dtype=torch.float).view(-1, 1)\n",
    "    edge_index = torch.tensor(list(graph.edges)).t().contiguous()\n",
    "    edge_attr = torch.tensor([graph.edges[edge]['mol_weight'] for edge in graph.edges], dtype=torch.float)\n",
    "    y = torch.tensor([label])  # Graph-level label\n",
    "\n",
    "    data = Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=y)\n",
    "    data_list.append(data)\n",
    "\n",
    "# Concatenate all data samples into a single PyG data object\n",
    "data = torch_geometric.data.Batch.from_data_list(data_list)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data into training and testing sets\n",
    "train_data, test_data = train_test_split(data, test_size=.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 291.3220929327453\n",
      "Epoch 10, Loss: 187.51650398398237\n",
      "Epoch 20, Loss: 26.978775560855865\n",
      "Epoch 30, Loss: 29.461252726614475\n",
      "Epoch 40, Loss: 30.913760513067245\n",
      "Epoch 50, Loss: 28.086616799235344\n",
      "Epoch 60, Loss: 27.01753768324852\n",
      "Epoch 70, Loss: 27.176073491573334\n",
      "Epoch 80, Loss: 27.016084015369415\n",
      "Epoch 90, Loss: 26.955724462866783\n",
      "Training completed.\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Initialize GNN model\n",
    "model = GCN(input_dim=data.x.shape[1], hidden_dim=128, output_dim=2)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Train the model\n",
    "model.train()\n",
    "for epoch in range(100):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    total_loss = 0\n",
    "    for data in train_data:\n",
    "        out = model(data)\n",
    "        loss = criterion(out, data.y.view(-1))\n",
    "        loss.backward()\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {total_loss}\")\n",
    "\n",
    "print(\"Training completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([1])\n",
      "Accuracy: 0.8\n"
     ]
    }
   ],
   "source": [
    "# Evaluation mode\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for data in test_data:\n",
    "        out = model(data)\n",
    "        predicted_labels = out.argmax(dim=1)\n",
    "        true_labels = data.y.view(-1)\n",
    "        correct += (predicted_labels == true_labels).sum().item()\n",
    "        total += len(true_labels)\n",
    "        print(predicted_labels, data.y)\n",
    "\n",
    "    accuracy = correct / total\n",
    "    print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXAMPLE OF GRAPHNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graphs: [<networkx.classes.graph.Graph object at 0x7f375a17dac0>, <networkx.classes.graph.Graph object at 0x7f375a17da30>, <networkx.classes.graph.Graph object at 0x7f375a17da00>, <networkx.classes.graph.Graph object at 0x7f375a17db80>, <networkx.classes.graph.Graph object at 0x7f375a17dfd0>]\n",
      "Labels: [0, 0, 0, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import random\n",
    "\n",
    "# Generate random graphs with labels\n",
    "num_graphs = 5\n",
    "graphs = []\n",
    "labels = []\n",
    "\n",
    "for _ in range(num_graphs):\n",
    "    # Generate a random graph\n",
    "    graph = nx.fast_gnp_random_graph(10, 0.3)\n",
    "    graphs.append(graph)\n",
    "    \n",
    "    # Assign a random label (Type 0 or Type 1)\n",
    "    label = random.choice([0, 1])\n",
    "    labels.append(label)\n",
    "\n",
    "print(\"Graphs:\", graphs)\n",
    "print(\"Labels:\", labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataBatch(x=[50, 16], edge_index=[2, 64], y=[5], batch=[50], ptr=[6])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch_geometric.data import Data\n",
    "import torch_geometric\n",
    "import torch\n",
    "\n",
    "# Convert NetworkX graphs to PyG data\n",
    "data_list = []\n",
    "for graph, label in zip(graphs, labels):\n",
    "    # Convert NetworkX graph to PyG data\n",
    "    edge_index = torch.tensor(list(graph.edges)).t().contiguous()\n",
    "    x = torch.randn(graph.number_of_nodes(), 16)  # Random node features (16 dimensions)\n",
    "    y = torch.tensor([label])  # Graph-level label\n",
    "    \n",
    "    data = Data(x=x, edge_index=edge_index, y=y)\n",
    "    data_list.append(data)\n",
    "\n",
    "\n",
    "# Concatenate all data samples into a single PyG data object\n",
    "data = torch_geometric.data.Batch.from_data_list(data_list)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(input_dim, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        # Global mean pooling to obtain graph-level representation\n",
    "        x = torch_geometric.nn.global_mean_pool(x, batch)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data into training and testing sets\n",
    "train_data, test_data = train_test_split(data, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Initialize GNN model\n",
    "model = GCN(input_dim=16, hidden_dim=32, output_dim=2)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Train the model\n",
    "model.train()\n",
    "for epoch in range(100):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    total_loss = 0\n",
    "    for data in train_data:\n",
    "        out = model(data)\n",
    "        loss = criterion(out, data.y.view(-1))\n",
    "        loss.backward()\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {total_loss}\")\n",
    "\n",
    "print(\"Training completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation mode\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for data in test_data:\n",
    "        out = model(data)\n",
    "        predicted_labels = out.argmax(dim=1)\n",
    "        true_labels = data.y.view(-1)\n",
    "        correct += (predicted_labels == true_labels).sum().item()\n",
    "        total += len(true_labels)\n",
    "\n",
    "    accuracy = correct / total\n",
    "    print(f\"Accuracy: {accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import networkx as nx\n",
    "from tqdm import tqdm\n",
    "from compound import Compound\n",
    "from reaction import Reaction\n",
    "from graph import Graph\n",
    "from data import Data\n",
    "\n",
    "# suppres rdkit warnings\n",
    "import rdkit\n",
    "from rdkit import RDLogger\n",
    "RDLogger.DisableLog('rdApp.*')\n",
    "\n",
    "# read data from csv\n",
    "cpds = pd.read_csv('../GNN_toxic/data/raw/compounds_final.csv', index_col=0) # containing toxicity\n",
    "rxns = pd.read_csv('data/reactions_final.csv', index_col=0)\n",
    "pairs = pd.read_csv('data/pairs_final.csv', index_col=0)\n",
    "cofactors = pd.read_csv('data/original/cofactors_KEGG.csv')\n",
    "\n",
    "# create class instances\n",
    "data = Data()\n",
    "graph = Graph(pairs=pairs)\n",
    "\n",
    "# Create a Compound object for each row in the DataFrame and add it to the data\n",
    "for index, row in cpds.iterrows():\n",
    "    entry = row['Entry']\n",
    "    name = row['Names']\n",
    "    formula = row['Formula']\n",
    "    mw = row['mol_weight']\n",
    "    smiles = row['SMILES']\n",
    "    is_cofactor = row['Entry'] in cofactors['Entry'].values\n",
    "    is_toxic = row['toxic']\n",
    "\n",
    "    compound = Compound(entry, name, formula, mw, smiles, is_cofactor, is_toxic)\n",
    "    data.add_element('compound', compound)\n",
    "\n",
    "# Create a Reaction object for each row in the DataFrame and add it to the data\n",
    "for index, row in rxns.iterrows():\n",
    "    entry = row['Entry']\n",
    "    name = row['Names']\n",
    "    compounds = row['Compound']\n",
    "    enzyme = row['EC Number']\n",
    "\n",
    "    reaction = Reaction(entry, name, compounds, enzyme)\n",
    "    data.add_element('reaction', reaction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# nodes: 8591 \n",
      "# edges: 30026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8591/8591 [00:14<00:00, 580.57it/s]\n",
      "100%|██████████| 30026/30026 [00:00<00:00, 218319.35it/s]\n",
      "100%|██████████| 30026/30026 [00:49<00:00, 604.14it/s] \n"
     ]
    }
   ],
   "source": [
    "# CREATE GRAPH\n",
    "graph.create_graph(data=data, pairs=pairs)\n",
    "\n",
    "graph.calculate_edge_mol_weight(data)\n",
    "graph.calculate_smiles_similarity(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct pathway predictions: 1\n",
      "Correct pathway predictions (%): 100.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "######### VALIDATION SET FROM nicepath ###########\n",
    "test_cases = pd.read_csv('data/original/test_cases.csv')\n",
    "test_cases['source'] = test_cases['Pathway '].apply(lambda x: x.split(',')[0])\n",
    "test_cases['target'] = test_cases['Pathway '].apply(lambda x: x.split(',')[len(x.split(','))-1])\n",
    "test_cases['paths_list'] = test_cases['Pathway '].apply(lambda x: x.split(','))\n",
    "\n",
    "''' Get just a single pathway from test_cases for testing '''\n",
    "test_cases = test_cases.iloc[0:1]\n",
    "\n",
    "paths = graph.validate(test_cases, 'mol_weight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display pathway to BIGG style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C00082', 'C00811', 'C01197', 'C01494', 'C05619', 'C00482', 'C05610', 'C02325', 'C01533']\n"
     ]
    }
   ],
   "source": [
    "''' Get the pathway from paths '''\n",
    "path = paths['Pathway'].iloc[0]\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C00082 tyr__L\n",
      "C00811 T4hcinnm\n",
      "C01197 34dhcinm\n",
      "C01494 fer\n",
      "C05619 Not found\n",
      "C00482 Not found\n",
      "C05610 Not found\n",
      "C02325 Not found\n",
      "C01533 Not found\n"
     ]
    }
   ],
   "source": [
    "for cpd in path:\n",
    "    bigg_cpd = graph.kegg_to_bigg_compound(cpd)        \n",
    "    print(cpd, bigg_cpd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_cases.iloc[20]['Pathway '])\n",
    "print(test_cases.iloc[42]['Pathway '])\n",
    "print(test_cases.iloc[47]['Pathway '])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kegg_cpd = 'C00084'\n",
    "bigg_cpd = graph.kegg_to_bigg_compound(kegg_cpd)\n",
    "print(bigg_cpd)\n",
    "\n",
    "kegg_rxn = 'R00084'\n",
    "bigg_rxn = graph.kegg_to_bigg_compound(kegg_rxn)\n",
    "print(bigg_rxn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1/0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C00082', 'C00355', 'C10447', 'C01197', 'C01494', 'C05619', 'C00482', 'C05610', 'C02325', 'C01533']\n",
      "7\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# p, idx, idxcom = graph.constrained_shortest_path('C00082', 'C01533', weight='mol_weight')\n",
    "for i in p: \n",
    "    print(i)\n",
    "    compound_list = i\n",
    "    for j in range(len(compound_list)-1):\n",
    "        cpd_a = compound_list[j]\n",
    "        cpd_b = compound_list[j+1]\n",
    "        ''' get pairs with source=cpd_a and target=cpd_b '''\n",
    "        pairs = graph.pairs[(graph.pairs['source'] == cpd_a) & (graph.pairs['target'] == cpd_b)]\n",
    "        ''' if len(pairs)=0 get pairs with source = cpd_b and target = cpd_a '''\n",
    "        if len(pairs) == 0:\n",
    "            pairs = graph.pairs[(graph.pairs['source'] == cpd_b) & (graph.pairs['target'] == cpd_a)]\n",
    "        print(len(pairs))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Study graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try cluster graph nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try similarity based on SMILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles1 = data.get_compound_by_id('C00223').smiles\n",
    "smiles2 = data.get_compound_by_id('C00323').smiles\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit import DataStructs\n",
    "\n",
    "ms = [Chem.MolFromSmiles(smiles1), Chem.MolFromSmiles(smiles2)]\n",
    "fs = [Chem.RDKFingerprint(x) for x in ms]\n",
    "s = DataStructs.FingerprintSimilarity(fs[0], fs[1])\n",
    "print('Similarity: '+str(s))\n",
    "\n",
    "\n",
    "smiles1 = data.get_compound_by_id('C00223').smiles\n",
    "smiles2 = data.get_compound_by_id('C12096').smiles\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit import DataStructs\n",
    "\n",
    "ms = [Chem.MolFromSmiles(smiles1), Chem.MolFromSmiles(smiles2)]\n",
    "fs = [Chem.RDKFingerprint(x) for x in ms]\n",
    "s = DataStructs.FingerprintSimilarity(fs[0], fs[1])\n",
    "print('Similarity: '+str(s))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

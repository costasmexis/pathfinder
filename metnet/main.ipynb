{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from compound import Compound\n",
    "from reaction import Reaction\n",
    "from graph import Graph\n",
    "from data import Data\n",
    "\n",
    "# read data from csv\n",
    "cpds = pd.read_csv('../GNN_toxic/data/raw/compounds_final.csv', index_col=0) # containing toxicity\n",
    "rxns = pd.read_csv('data/reactions_final.csv', index_col=0)\n",
    "pairs = pd.read_csv('data/pairs_final.csv', index_col=0)\n",
    "cofactors = pd.read_csv('data/original/cofactors_KEGG.csv')\n",
    "\n",
    "# create class instances\n",
    "data = Data()\n",
    "graph = Graph(pairs=pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Compound object for each row in the DataFrame and add it to the data\n",
    "for index, row in cpds.iterrows():\n",
    "    entry = row['Entry']\n",
    "    name = row['Names']\n",
    "    formula = row['Formula']\n",
    "    mw = row['mol_weight']\n",
    "    smiles = row['SMILES']\n",
    "    is_cofactor = row['Entry'] in cofactors['Entry'].values\n",
    "    is_toxic = row['toxic']\n",
    "\n",
    "    compound = Compound(entry, name, formula, mw, smiles, is_cofactor, is_toxic)\n",
    "    data.add_element('compound', compound)\n",
    "\n",
    "# Create a Reaction object for each row in the DataFrame and add it to the data\n",
    "for index, row in rxns.iterrows():\n",
    "    entry = row['Entry']\n",
    "    name = row['Names']\n",
    "    compounds = row['Compound']\n",
    "    enzyme = row['EC Number']\n",
    "\n",
    "    reaction = Reaction(entry, name, compounds, enzyme)\n",
    "    data.add_element('reaction', reaction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# nodes: 8591 \n",
      "# edges: 30026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8591/8591 [00:00<00:00, 671410.63it/s]\n"
     ]
    }
   ],
   "source": [
    "# number of times a metabolite apperas on pairs dataset\n",
    "graph.get_number_of_occurences(pairs)\n",
    "graph.create_graph(data=data, pairs=pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30026/30026 [00:00<00:00, 656375.82it/s]\n"
     ]
    }
   ],
   "source": [
    "graph.calculate_edge_mol_weight(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct pathway predictions: 14\n",
      "Correct pathway predictions (%): 28.0\n"
     ]
    }
   ],
   "source": [
    "######### VALIDATION SET FROM nicepath ###########\n",
    "test_cases = pd.read_csv('data/original/test_cases.csv')\n",
    "test_cases['source'] = test_cases['Pathway '].apply(lambda x: x.split(',')[0])\n",
    "test_cases['target'] = test_cases['Pathway '].apply(lambda x: x.split(',')[len(x.split(','))-1])\n",
    "test_cases['paths_list'] = test_cases['Pathway '].apply(lambda x: x.split(','))\n",
    "paths = graph.validate(test_cases, 'mol_weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity: 0.989145183175034\n",
      "Similarity: 0.5102379634753735\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try cluster graph nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try similarity based on SMILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles1 = data.get_compound_by_id('C00223').smiles\n",
    "smiles2 = data.get_compound_by_id('C00323').smiles\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit import DataStructs\n",
    "\n",
    "ms = [Chem.MolFromSmiles(smiles1), Chem.MolFromSmiles(smiles2)]\n",
    "fs = [Chem.RDKFingerprint(x) for x in ms]\n",
    "s = DataStructs.FingerprintSimilarity(fs[0], fs[1])\n",
    "print('Similarity: '+str(s))\n",
    "\n",
    "\n",
    "smiles1 = data.get_compound_by_id('C00223').smiles\n",
    "smiles2 = data.get_compound_by_id('C12096').smiles\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit import DataStructs\n",
    "\n",
    "ms = [Chem.MolFromSmiles(smiles1), Chem.MolFromSmiles(smiles2)]\n",
    "fs = [Chem.RDKFingerprint(x) for x in ms]\n",
    "s = DataStructs.FingerprintSimilarity(fs[0], fs[1])\n",
    "print('Similarity: '+str(s))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
